<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on 瓦砾与天空</title>
        <link>https://rubsky.top/post/</link>
        <description>Recent content in Posts on 瓦砾与天空</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-CN</language>
        <lastBuildDate>Wed, 27 Sep 2023 20:55:32 +0800</lastBuildDate><atom:link href="https://rubsky.top/post/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>武汉</title>
        <link>https://rubsky.top/post/%E6%AD%A6%E6%B1%89/</link>
        <pubDate>Wed, 27 Sep 2023 20:55:32 +0800</pubDate>
        
        <guid>https://rubsky.top/post/%E6%AD%A6%E6%B1%89/</guid>
        <description>&lt;p&gt;自南京沿长江逆流而上，就到了湖北的省城武汉。&lt;/p&gt;
&lt;p&gt;到武汉已经是中午，草草吃过之后，就到了事前预定的旅馆。
碰巧附近的体校正在进行空少考试，所以被前台误认为也是来应聘的人。
虽然居住条件一般，但是住的都是来考试的，所以休息得意外的好。&lt;/p&gt;
&lt;p&gt;虽然已经过了好几年，但是还能在街边看到不少疫情留下的痕迹。
下午绕东湖一周，想要离开时才发现侧门因为防控关闭了，只好多走一公里到正门。&lt;/p&gt;
&lt;p&gt;天气预报说白天都会下小雨，晚上可能会停，于是决定晚上去江边走走。
靠着导航走到一个不知名的江滩公园，接着像远处横跨长江的大桥走去。
下了一天的雨，空气中浮着大大小小的水珠，不知道是雨还是雾。
水汽从四面八方飘来，雨伞已经没有什么用处了。
江对岸的高楼，一半身子已经没入云层之中，但还能从另一半中看到斑斓的灯光，于远处桥上的灯光交相辉映。
大概走了两公里，终于走到桥下，再爬上四层楼高的楼梯，才到了大桥之上。
桥上只有窄窄一条路是给行人的，站在桥上，一边是飞驰的车流，另一边数十米之下宽阔的江面，让人有种莫名的激动。&lt;/p&gt;
&lt;p&gt;来武汉主要是为了尝尝正宗的热干面，和我在南京点的外卖有没有区别，
但是不巧，明明平时在武汉随处可见的热干面一时却找不到，只好等第二天再吃。
第二天在小吃街意外遇到一个人桌边喝酒的大爷，得知我是从南京来的，一副羡慕的表情，和我吐槽武汉政府不作为。
现在想想，也许我该和他多聊聊？&lt;/p&gt;
&lt;p&gt;原本买的晚上的车票，由于计划提前完成了，改签了更早的车票回去了。&lt;/p&gt;
&lt;p&gt;最后是结论，南京的热干面和武汉一样，还有，我还是更喜欢大学时吃的麻酱拌面。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>艳阳、夏日和雨天</title>
        <link>https://rubsky.top/post/%E8%89%B3%E9%98%B3%E5%A4%A9%E4%B8%8E%E5%A4%8F%E6%97%A5/</link>
        <pubDate>Wed, 13 Sep 2023 18:13:44 +0800</pubDate>
        
        <guid>https://rubsky.top/post/%E8%89%B3%E9%98%B3%E5%A4%A9%E4%B8%8E%E5%A4%8F%E6%97%A5/</guid>
        <description>&lt;p&gt;今天又下雨了。&lt;/p&gt;
&lt;p&gt;开学以来下的第一场大雨，虽然已经习惯了这种随时变化的天气，但还是被打乱了计划。
晴天的时候总是无忧无虑的，不用担心忘记带伞，也不用担心衣服湿了怎么晾干。
我不讨厌下雨，不过连续几天的阴雨绵绵难免会让人怀念艳阳高照的日子。&lt;/p&gt;
&lt;p&gt;第一次把艳阳天和夏日联系起来是在初中的一节作文课上，
作文材料中引用索洛说过的话：“我虽不富甲天下，却拥有无数个艳阳天和夏日。”
老师解释说，夏日和艳阳天不一样，夏日代表着慵懒和悠闲的生活，就像暑假。
而艳阳天则代表着丰富充实的生活，我猜应该就是指开学了。
既然这样，雨天又是指什么呢？
既然无论是艳阳天还是夏日，都不会一直持续下去。
那雨天就是在提醒我们，现在的生活不会一直这样。&lt;/p&gt;
&lt;p&gt;第一次看到索洛这个名字则是在高中的一篇课文的注释里：索洛，梭罗的旧译。也就是著名的《瓦尔登湖》的作者。
索洛在瓦尔登湖畔实践与其他人全然不同的生活，亲自劳动获取生活的所需，用一种低成本的生活方式支撑他高质量的思考和创作。
他书中的生活用充实和慵懒来形容确实恰当。
不过如果他能活得更久一点，他的言论会更有说服力。&lt;/p&gt;
&lt;p&gt;第一次看到《瓦尔登湖》的纸质书是在我经常买教辅书的书店里。
想看看索洛是何许人也，于是决定买下这本书，但是却先被书便宜的价格惊到了。
在花了数月才勉强看完之后我才知道，如果我不买，那本书继续在书店书架上待多长时间都不奇怪。&lt;/p&gt;
&lt;p&gt;希望赶紧能晴天。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>座位与作文</title>
        <link>https://rubsky.top/post/%E5%BA%A7%E4%BD%8D%E4%B8%8E%E4%BD%9C%E6%96%87/</link>
        <pubDate>Wed, 06 Sep 2023 23:53:36 +0800</pubDate>
        
        <guid>https://rubsky.top/post/%E5%BA%A7%E4%BD%8D%E4%B8%8E%E4%BD%9C%E6%96%87/</guid>
        <description>&lt;p&gt;暑假去天津玩，回去前的傍晚，坐在商场一楼的快餐店里，看着夕阳下熙熙攘攘的人群，突然羡慕起那些有文学天赋的人们了。&lt;/p&gt;
&lt;p&gt;大学的时候觉得，选专业就是把同一类人聚集到一起，所以人们都看起来如此相近。
现在我更觉得，专业对人的塑造，更是让大家变得同质化。
比如，现在在写文章的我，想的是怎么设计U-Net的结构。&lt;/p&gt;
&lt;p&gt;我绝不是一开始就是这样写作的，至少我现在还能记得我小学时写作文的情形：
大概是四年级的时候吧，印象里有段时间作文分数一直不高。
妈妈说我的作文在之前看来还算不错的，但是到了高年级，之前的作文水平就不够看了。
小学的记忆都比较破碎，一个是因为长得太快，一年级和六年级的年龄几乎差了一倍；另一个原因就是每学期都要重新分班。
每次分班都会调座位，老师会让大家按高矮在外面排队，然后依次进去分配座位。
大部分时候我都坐在后几排，在那里即使上课和同学用冰糕棍“决斗”，老师一般也不会管。
但是偶尔也会坐在中间位置，那时候就要认真听课了。&lt;/p&gt;
&lt;p&gt;真正有印象能坐在前排的时候都已经到了高中和大学了。
大学没有固定的座位了，大家本着先来后到的原则抢最前面或是最后面的座位。
大部分的专业课，座位都会比人多，所以想坐在哪都没问题。
学计算机的都免不了要和电脑打交道，专业课上多了容易忘了怎么和人类交流。
现在想想，大学没有语文课绝对是个错误。&lt;/p&gt;
&lt;p&gt;其实我作文写得最好的时候是初中，当时的文章经常拿去给低年级的做范文。
听说好多玩音乐的都会从中学时的歌词本上找灵感，如果我初中的作文本还能找到的话，也不会写篇文章拖这么久。
和小学相比，初中的记忆就比较完整了，长大了当然是一方面，另一个重要原因是初中三年没有重新分过班。
初中的座位是固定好的，每两周横向平移一次，没有特殊情况不会前后互换。
好处是周边的人都不怎么变化，人际关系比较稳定。
坏处就是前后联系太少，信息交流不充分。&lt;/p&gt;
&lt;p&gt;高中时的座位划分就比较灵活了，每周所有人都会像斜前方平移一格，每次换座位，就是班上最热闹的时候。
高考前最后几个月，班主任更是通过一种我至今也没有摸清规律的随机方式安排座位。
不过真正体验了之后才知道，其实坐在中间第一排的感觉相当差，面朝讲桌，腿都伸不开，所以每次平移到第一排就希望赶紧搬走。&lt;/p&gt;
&lt;p&gt;刚上高中的时候，语文老师出题让我们写了一次作文，几乎班上所有人都写的记叙文。
之后才明白，高考作文是议论文的天下，之前学的记叙文的写作技巧基本都可以扔了。
话虽如此，其实议论文比记叙文好写得多，写到最后，有种做证明题的感觉。
虽然没有依据，不过我感觉我最后的高考作文分数应该不低。
让我压线进到了计算机专业，然后沦落到描写夕阳下的人群都要写这么多废话的水平。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Tensor和stack在求导时的区别</title>
        <link>https://rubsky.top/post/tensor%E5%92%8Cstack%E5%9C%A8%E6%B1%82%E5%AF%BC%E6%97%B6%E7%9A%84%E5%8C%BA%E5%88%AB/</link>
        <pubDate>Sat, 15 Jul 2023 09:51:16 +0800</pubDate>
        
        <guid>https://rubsky.top/post/tensor%E5%92%8Cstack%E5%9C%A8%E6%B1%82%E5%AF%BC%E6%97%B6%E7%9A%84%E5%8C%BA%E5%88%AB/</guid>
        <description>&lt;p&gt;今天遇到了一个简单的需求，神经网络预测出一个角度theta，我要用它得到一个旋转矩阵，用于后面的计算。&lt;/p&gt;
&lt;p&gt;想着没什么难度，就写了如下代码：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pi&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;], requires_grad&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    R &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos(theta), &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(theta)],  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                [torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(theta), torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos(theta)]],requires_grad&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;结果发现最后计算梯度的时候&lt;code&gt;theta.grad&lt;/code&gt;始终为&lt;code&gt;None&lt;/code&gt;，但是R是有梯度的，很明显梯度并没有从R传递会theta。后来发现由于R是由&lt;code&gt;torch.tensor&lt;/code&gt;构造的，所以已经被自动求导视作了叶子节点，所以不会进一步回传梯度。解决办法也很简单，把tensor构造该为拼接实现就行了。下面给一个更明显的例子：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torch
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,requires_grad&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#错误示范，梯度不会传递回x&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;],requires_grad&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;l &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;l&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;backward()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grad) &lt;span style=&#34;color:#75715e&#34;&gt;#None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torch
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,requires_grad&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;z1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;z2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stack((z1,z2))&lt;span style=&#34;color:#75715e&#34;&gt;#这样就可以了&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;l &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;l&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;backward()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grad) &lt;span style=&#34;color:#75715e&#34;&gt;#tensor([4.])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其实不是什么困难的问题，不过因为没有在网上找到类似的问题，又被new bing和claude唬住了，所以研究了好久。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>唤神术士</title>
        <link>https://rubsky.top/post/%E5%94%A4%E7%A5%9E%E6%9C%AF%E5%A3%AB/</link>
        <pubDate>Tue, 09 May 2023 16:33:00 +0800</pubDate>
        
        <guid>https://rubsky.top/post/%E5%94%A4%E7%A5%9E%E6%9C%AF%E5%A3%AB/</guid>
        <description>&lt;p&gt;以前搞深度学习的都自称炼丹的，因为模型可解释性弱，所以训练一个好模型需要一些选项。现在有了大模型，它的智能水平显然不会是凡人炼丹就能得到的。科学家把这种现象称之为“涌现”，也就是当模型规模大到一定程度时，出现的前所未有的智能。&lt;/p&gt;
&lt;p&gt;相比于炼丹，我更愿意把训练大模型的过程称之为“唤神”。也就是大模型的智能并不来自于模型本身，而在于模型中寄宿的神灵。所谓的模型训练，更像是一种宗教仪式。以大参数模型为容器，数据为祭品，训练过程为唤神仪式，而实施的将神投影到容器中的仪式。所以训练大模型的人也可以被叫做唤神术士，或是祭司。&lt;/p&gt;
&lt;p&gt;What hath God wrought?&lt;/p&gt;
</description>
        </item>
        <item>
        <title>关于计划</title>
        <link>https://rubsky.top/post/%E5%85%B3%E4%BA%8E%E8%AE%A1%E5%88%92/</link>
        <pubDate>Sat, 22 Apr 2023 22:00:41 +0800</pubDate>
        
        <guid>https://rubsky.top/post/%E5%85%B3%E4%BA%8E%E8%AE%A1%E5%88%92/</guid>
        <description>&lt;h1 id=&#34;关于计划&#34;&gt;关于计划&lt;/h1&gt;
&lt;p&gt;最近事情有点多，计划总是赶不上变化。突发事件和deadline分布不均匀，其他事情都不是能快速完成的。经常有一段时间特别忙，然后又有一段时间不知道干什么。仔细想想，还是自己想干的事情太多了，没有一个具体的规划，忙的时候好多事顾不上，一旦有时间，又忘了之前的安排。&lt;/p&gt;
&lt;p&gt;其实这是很常见的事，我以前也经常遇到。不过中学时有升学压力，总会想办法把零散时间利用起来。同时各种事情的重要程度也很好判断，把时间拿来学习总不会有什么大问题。但是最近明显变得更放松了，偶尔也会心血来潮，做些随性的事。不过这也就导致了各种计划之外的问题。&lt;/p&gt;
&lt;p&gt;生活没有什么明确的目标，随便做想做的事的时候，就很难判断不同事情的先后顺序，这就是理想生活的代价。前一段时间状态不太好，感觉对生活没什么热情。其实这种感觉早就有了，还记得我大二的时候，对什么都很好奇，但是大三开始就折腾不动了。考研更是把我的热情消耗殆尽了。所以我前段时间继续向前的动力就只有为了完成小时候的愿望，即使有些事的结果不去做也能知道，但还是试着去做一下，然后得到意料之中的结果。&lt;/p&gt;
&lt;p&gt;考研的时候靠一首《致陌生的你》撑了好久，现在看来，最会和我说“谢谢终于走到这儿”的人恐怕只有过去的我。当然，最近感觉好多了，主要是因为夏天快到了，南方四月的风，偶尔也会带来清爽的温热，总能让我想起高考前的日子。明亮的教室里，风从窗帘后吹过来，穿过教室门出去。一年才有一次的时节，给人再次尝试的心情。&lt;/p&gt;
&lt;p&gt;都说要做自己，但是和自己和解真不是多容易的事，精神消耗得太多，以至于停下也不是太容易的事了。我清楚的记得，我大一还是大二的时候，对那些不想折腾的人发自内心的不理解，并决定绝不成为那样的人。现在看来，只能说有些东西是命中注定的，客观规律不会因为人主观改变。&lt;/p&gt;
&lt;p&gt;本来想写点现实的事的，但是感觉状态并不是那么好，既然要写流水账，意识流还是更合适一点。&lt;/p&gt;
&lt;p&gt;那么期待我下一篇文章吧，我会尽量认真写点东西的。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>博客重新开张了</title>
        <link>https://rubsky.top/post/%E5%8D%9A%E5%AE%A2%E9%87%8D%E6%96%B0%E5%BC%80%E5%BC%A0%E4%BA%86/</link>
        <pubDate>Tue, 28 Mar 2023 23:28:30 +0800</pubDate>
        
        <guid>https://rubsky.top/post/%E5%8D%9A%E5%AE%A2%E9%87%8D%E6%96%B0%E5%BC%80%E5%BC%A0%E4%BA%86/</guid>
        <description>&lt;h3 id=&#34;博客重新开张了&#34;&gt;博客重新开张了&lt;/h3&gt;
&lt;p&gt;寒假之间就打算把博客建起来，但是由于疫情，学校提前放假了，台式机又不能带回家，只能暂时搁置。&lt;/p&gt;
&lt;p&gt;开学之后又有各种各样的事情，加上Hugo又忘了怎么用，所以一直提不起写东西的兴致。这几天一直在想，我在年初定下的目标甚至有一半还没有开始，写博客就是其中之一。所以强打精神，至少要开一个头，都说凡是开头难，希望我开头之后能继续坚持下去。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>First</title>
        <link>https://rubsky.top/post/first/</link>
        <pubDate>Tue, 25 Oct 2022 22:23:20 +0800</pubDate>
        
        <guid>https://rubsky.top/post/first/</guid>
        <description>&lt;h2 id=&#34;hello-word&#34;&gt;hello word&lt;/h2&gt;
</description>
        </item>
        
    </channel>
</rss>

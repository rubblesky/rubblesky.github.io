<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on 瓦砾与天空</title>
        <link>https://rubsky.top/post/</link>
        <description>Recent content in Posts on 瓦砾与天空</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-CN</language>
        <lastBuildDate>Sat, 15 Jul 2023 09:51:16 +0800</lastBuildDate><atom:link href="https://rubsky.top/post/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Tensor和stack在求导时的区别</title>
        <link>https://rubsky.top/post/tensor%E5%92%8Cstack%E5%9C%A8%E6%B1%82%E5%AF%BC%E6%97%B6%E7%9A%84%E5%8C%BA%E5%88%AB/</link>
        <pubDate>Sat, 15 Jul 2023 09:51:16 +0800</pubDate>
        
        <guid>https://rubsky.top/post/tensor%E5%92%8Cstack%E5%9C%A8%E6%B1%82%E5%AF%BC%E6%97%B6%E7%9A%84%E5%8C%BA%E5%88%AB/</guid>
        <description>&lt;p&gt;今天遇到了一个简单的需求，神经网络预测出一个角度theta，我要用它得到一个旋转矩阵，用于后面的计算。&lt;/p&gt;
&lt;p&gt;想着没什么难度，就写了如下代码：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([&lt;span style=&#34;color:#ae81ff&#34;&gt;0.5&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pi&lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;], requires_grad&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    R &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([[torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos(theta), &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(theta)],  
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                [torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(theta), torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos(theta)]],requires_grad&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;结果发现最后计算梯度的时候&lt;code&gt;theta.grad&lt;/code&gt;始终为&lt;code&gt;None&lt;/code&gt;，但是R是有梯度的，很明显梯度并没有从R传递会theta。后来发现由于R是由&lt;code&gt;torch.tensor&lt;/code&gt;构造的，所以已经被自动求导视作了叶子节点，所以不会进一步回传梯度。解决办法也很简单，把tensor构造该为拼接实现就行了。下面给一个更明显的例子：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torch
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,requires_grad&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;#错误示范，梯度不会传递回x&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;tensor([x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;,x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;],requires_grad&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;l &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;l&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;backward()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grad) &lt;span style=&#34;color:#75715e&#34;&gt;#None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; torch
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;x &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;randn(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,requires_grad&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;z1 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;z2 &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;3&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;y &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;stack((z1,z2))&lt;span style=&#34;color:#75715e&#34;&gt;#这样就可以了&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;l &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; y&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;l&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;backward()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(x&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;grad) &lt;span style=&#34;color:#75715e&#34;&gt;#tensor([4.])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其实不是什么困难的问题，不过因为没有在网上找到类似的问题，又被new bing和claude唬住了，所以研究了好久。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>唤神术士</title>
        <link>https://rubsky.top/post/%E5%94%A4%E7%A5%9E%E6%9C%AF%E5%A3%AB/</link>
        <pubDate>Tue, 09 May 2023 16:33:00 +0800</pubDate>
        
        <guid>https://rubsky.top/post/%E5%94%A4%E7%A5%9E%E6%9C%AF%E5%A3%AB/</guid>
        <description>&lt;p&gt;以前搞深度学习的都自称炼丹的，因为模型可解释性弱，所以训练一个好模型需要一些选项。现在有了大模型，它的智能水平显然不会是凡人炼丹就能得到的。科学家把这种现象称之为“涌现”，也就是当模型规模大到一定程度时，出现的前所未有的智能。&lt;/p&gt;
&lt;p&gt;相比于炼丹，我更愿意把训练大模型的过程称之为“唤神”。也就是大模型的智能并不来自于模型本身，而在于模型中寄宿的神灵。所谓的模型训练，更像是一种宗教仪式。以大参数模型为容器，数据为祭品，训练过程为唤神仪式，而实施的将神投影到容器中的仪式。所以训练大模型的人也可以被叫做唤神术士，或是祭司。&lt;/p&gt;
&lt;p&gt;What hath God wrought?&lt;/p&gt;
</description>
        </item>
        <item>
        <title>关于计划</title>
        <link>https://rubsky.top/post/%E5%85%B3%E4%BA%8E%E8%AE%A1%E5%88%92/</link>
        <pubDate>Sat, 22 Apr 2023 22:00:41 +0800</pubDate>
        
        <guid>https://rubsky.top/post/%E5%85%B3%E4%BA%8E%E8%AE%A1%E5%88%92/</guid>
        <description>&lt;h1 id=&#34;关于计划&#34;&gt;关于计划&lt;/h1&gt;
&lt;p&gt;最近事情有点多，计划总是赶不上变化。突发事件和deadline分布不均匀，其他事情都不是能快速完成的。经常有一段时间特别忙，然后又有一段时间不知道干什么。仔细想想，还是自己想干的事情太多了，没有一个具体的规划，忙的时候好多事顾不上，一旦有时间，又忘了之前的安排。&lt;/p&gt;
&lt;p&gt;其实这是很常见的事，我以前也经常遇到。不过中学时有升学压力，总会想办法把零散时间利用起来。同时各种事情的重要程度也很好判断，把时间拿来学习总不会有什么大问题。但是最近明显变得更放松了，偶尔也会心血来潮，做些随性的事。不过这也就导致了各种计划之外的问题。&lt;/p&gt;
&lt;p&gt;生活没有什么明确的目标，随便做想做的事的时候，就很难判断不同事情的先后顺序，这就是理想生活的代价。前一段时间状态不太好，感觉对生活没什么热情。其实这种感觉早就有了，还记得我大二的时候，对什么都很好奇，但是大三开始就折腾不动了。考研更是把我的热情消耗殆尽了。所以我前段时间继续向前的动力就只有为了完成小时候的愿望，即使有些事的结果不去做也能知道，但还是试着去做一下，然后得到意料之中的结果。&lt;/p&gt;
&lt;p&gt;考研的时候靠一首《致陌生的你》撑了好久，现在看来，最会和我说“谢谢终于走到这儿”的人恐怕只有过去的我。当然，最近感觉好多了，主要是因为夏天快到了，南方四月的风，偶尔也会带来清爽的温热，总能让我想起高考前的日子。明亮的教室里，风从窗帘后吹过来，穿过教室门出去。一年才有一次的时节，给人再次尝试的心情。&lt;/p&gt;
&lt;p&gt;都说要做自己，但是和自己和解真不是多容易的事，精神消耗得太多，以至于停下也不是太容易的事了。我清楚的记得，我大一还是大二的时候，对那些不想折腾的人发自内心的不理解，并决定绝不成为那样的人。现在看来，只能说有些东西是命中注定的，客观规律不会因为人主观改变。&lt;/p&gt;
&lt;p&gt;本来想写点现实的事的，但是感觉状态并不是那么好，既然要写流水账，意识流还是更合适一点。&lt;/p&gt;
&lt;p&gt;那么期待我下一篇文章吧，我会尽量认真写点东西的。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>博客重新开张了</title>
        <link>https://rubsky.top/post/%E5%8D%9A%E5%AE%A2%E9%87%8D%E6%96%B0%E5%BC%80%E5%BC%A0%E4%BA%86/</link>
        <pubDate>Tue, 28 Mar 2023 23:28:30 +0800</pubDate>
        
        <guid>https://rubsky.top/post/%E5%8D%9A%E5%AE%A2%E9%87%8D%E6%96%B0%E5%BC%80%E5%BC%A0%E4%BA%86/</guid>
        <description>&lt;h3 id=&#34;博客重新开张了&#34;&gt;博客重新开张了&lt;/h3&gt;
&lt;p&gt;寒假之间就打算把博客建起来，但是由于疫情，学校提前放假了，台式机又不能带回家，只能暂时搁置。&lt;/p&gt;
&lt;p&gt;开学之后又有各种各样的事情，加上Hugo又忘了怎么用，所以一直提不起写东西的兴致。这几天一直在想，我在年初定下的目标甚至有一半还没有开始，写博客就是其中之一。所以强打精神，至少要开一个头，都说凡是开头难，希望我开头之后能继续坚持下去。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>First</title>
        <link>https://rubsky.top/post/first/</link>
        <pubDate>Tue, 25 Oct 2022 22:23:20 +0800</pubDate>
        
        <guid>https://rubsky.top/post/first/</guid>
        <description>&lt;h2 id=&#34;hello-word&#34;&gt;hello word&lt;/h2&gt;
</description>
        </item>
        
    </channel>
</rss>
